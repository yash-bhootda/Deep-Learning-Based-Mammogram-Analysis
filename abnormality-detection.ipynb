{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"5bde04c0-d9b9-4ca4-9b78-0724f4520da2","_uuid":"2a9eec106f03717c5e807ade1ccf7c65f7ec0ab1","trusted":true},"outputs":[{"ename":"AttributeError","evalue":"module 'tensorflow' has no attribute 'placeholder'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32md:\\Projects\\Medical_Img\\ZindaHoonKaafiHai\\abnormality-detection.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m     test_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mddsm-mammography\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtraining10_4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtraining10_4.tfrecords\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [test_files], \u001b[39m11178\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_conv2d_batch_norm\u001b[39m(\u001b[39minput\u001b[39m, filters, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), stride\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), training \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mplaceholder(dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mbool, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis_training\u001b[39m\u001b[39m\"\u001b[39m), epsilon\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, lambd\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=196'>197</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39m'\u001b[39m\u001b[39mlayer_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mname) \u001b[39mas\u001b[39;00m scope:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=197'>198</a>\u001b[0m         conv \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mconv2d(\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=198'>199</a>\u001b[0m             \u001b[39minput\u001b[39m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=199'>200</a>\u001b[0m             filters\u001b[39m=\u001b[39mfilters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mname\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/Medical_Img/ZindaHoonKaafiHai/abnormality-detection.ipynb#W1sZmlsZQ%3D%3D?line=207'>208</a>\u001b[0m         )\n","\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"]}],"source":["## Batch generator with optional filenames parameter which will also return the filenames of the images\n","## so that they can be identified\n","def get_batches(X, y, batch_size, filenames=None, distort=False):\n","    # Shuffle X,y\n","    shuffled_idx = np.arange(len(y))\n","    np.random.shuffle(shuffled_idx)\n","    i, h, w, c = X.shape\n","\n","    # Enumerate indexes by steps of batch_size\n","    for i in range(0, len(y), batch_size):\n","        batch_idx = shuffled_idx[i:i + batch_size]\n","        X_return = X[batch_idx]\n","\n","        # do random flipping of images\n","        coin = np.random.binomial(1, 0.5, size=None)\n","        if coin and distort:\n","            X_return = X_return[..., ::-1, :]\n","\n","        if filenames is None:\n","            yield X_return, y[batch_idx]\n","        else:\n","            yield X_return, y[batch_idx], filenames[batch_idx]\n","            \n","def _scale_input_data(X, contrast=None, mu=104.1353, scale=255.0):\n","    # if we are adjusting contrast do that\n","    if contrast and contrast != 1.0:\n","        X_adj = tf.image.adjust_contrast(X, contrast)\n","    else:\n","        X_adj = X\n","\n","    # cast to float\n","    if X_adj.dtype != tf.float32:\n","        X_adj = tf.cast(X_adj, dtype=tf.float32)\n","\n","    # center the pixel data\n","    X_adj = tf.subtract(X_adj, mu, name=\"centered_input\")\n","\n","    # scale the data\n","    X_adj = tf.divide(X_adj, scale)\n","\n","    return X_adj\n","\n","# Function to do the data augmentation on the GPU instead of the CPU, doing it on the CPU significantly slowed down training\n","# Taken from https://becominghuman.ai/data-augmentation-on-gpu-in-tensorflow-13d14ecf2b19\n","def augment(images, labels,\n","            horizontal_flip=False,\n","            vertical_flip=False,\n","            augment_labels=False,\n","            mixup=0):  # Mixup coeffecient, see https://arxiv.org/abs/1710.09412.pdf\n","\n","    # My experiments showed that casting on GPU improves training performance\n","    if images.dtype != tf.float32:\n","        images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n","\n","    with tf.name_scope('augmentation'):\n","        shp = tf.shape(images)\n","        batch_size, height, width = shp[0], shp[1], shp[2]\n","        width = tf.cast(width, tf.float32)\n","        height = tf.cast(height, tf.float32)\n","\n","        # The list of affine transformations that our image will go under.\n","        # Every element is Nx8 tensor, where N is a batch size.\n","        transforms = []\n","        identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n","        if horizontal_flip:\n","            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n","            flip_transform = tf.convert_to_tensor(\n","                [-1., 0., width, 0., 1., 0., 0., 0.], dtype=tf.float32)\n","            transforms.append(\n","                tf.where(coin,\n","                         tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n","                         tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n","\n","        if vertical_flip:\n","            coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n","            flip_transform = tf.convert_to_tensor(\n","                [1, 0, 0, 0, -1, height, 0, 0], dtype=tf.float32)\n","            transforms.append(\n","                tf.where(coin,\n","                         tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n","                         tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n","\n","        if transforms:\n","            images = tf.contrib.image.transform(\n","                images,\n","                tf.contrib.image.compose_transforms(*transforms),\n","                interpolation='BILINEAR')  # or 'NEAREST'\n","\n","            if augment_labels:\n","                labels = tf.contrib.image.transform(\n","                    labels,\n","                    tf.contrib.image.compose_transforms(*transforms),\n","                    interpolation='BILINEAR')  # or 'NEAREST'\n","\n","        def cshift(values):  # Circular shift in batch dimension\n","            return tf.concat([values[-1:, ...], values[:-1, ...]], 0)\n","\n","        if mixup > 0:\n","            beta = tf.distributions.Beta(mixup, mixup)\n","            lam = beta.sample(batch_size)\n","            ll = tf.expand_dims(tf.expand_dims(tf.expand_dims(lam, -1), -1), -1)\n","            images = ll * images + (1 - ll) * cshift(images)\n","            labels = lam * labels + (1 - lam) * cshift(labels)\n","\n","    return images, labels\n","\n","## load weights from a checkpoint, excluding any or including specified vars and returning initializer function\n","def load_weights(model_name, exclude=None, include=None):\n","    model_path = os.path.join(\"model\", model_name + \".ckpt\")\n","\n","    variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=exclude, include=include)\n","    init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n","\n","    return init_fn\n","\n","## read data from tfrecords file\n","def read_and_decode_single_example(filenames, label_type='label_normal', normalize=False, distort=False, num_epochs=None):\n","    filename_queue = tf.train.string_input_producer(filenames, num_epochs=num_epochs)\n","\n","    reader = tf.TFRecordReader()\n","\n","    if label_type != 'label':\n","        label_type = 'label_' + label_type\n","\n","    _, serialized_example = reader.read(filename_queue)\n","    if label_type != 'label_mask':\n","        features = tf.parse_single_example(\n","            serialized_example,\n","            features={\n","                'label': tf.FixedLenFeature([], tf.int64),\n","                'label_normal': tf.FixedLenFeature([], tf.int64),\n","                'image': tf.FixedLenFeature([], tf.string)\n","            })\n","\n","        # extract the data\n","        label = features[label_type]\n","        image = tf.decode_raw(features['image'], tf.uint8)\n","\n","        # reshape and scale the image\n","        image = tf.reshape(image, [299, 299, 1])\n","\n","        # random flipping of image\n","        if distort:\n","            image = tf.image.random_flip_left_right(image)\n","            image = tf.image.random_flip_up_down(image)\n","\n","    else:\n","        features = tf.parse_single_example(\n","            serialized_example,\n","            features={\n","                # We know the length of both fields. If not the\n","                # tf.VarLenFeature could be used\n","                'label': tf.FixedLenFeature([], tf.string),\n","                'image': tf.FixedLenFeature([], tf.string)\n","            })\n","\n","        label = tf.decode_raw(features['label'], tf.uint8)\n","        image = tf.decode_raw(features['image'], tf.uint8)\n","\n","        label = tf.cast(label, tf.int32)\n","        # image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n","\n","        image = tf.reshape(image, [288, 288, 1])\n","        label = tf.reshape(label, [288, 288, 1])\n","\n","        # if distort:\n","        #     image, label = _image_random_flip(image, label)\n","\n","    if normalize:\n","        image = tf.image.per_image_standardization(image)\n","\n","    # return the image and the label\n","    return image, label\n","\n","## Load the training data and return a list of the tfrecords file and the size of the dataset\n","## Multiple data sets have been created for this project, which one to be used can be set with the type argument\n","def get_training_data(what=10):\n","    if what == 10:\n","        train_path_10 = os.path.join(\"..\", \"input\", \"ddsm-mammography\", \"training10_0\", \"training10_0.tfrecords\")\n","        train_path_11 = os.path.join(\"..\", \"input\", \"ddsm-mammography\", \"training10_1\",\"training10_1.tfrecords\")\n","        train_path_12 = os.path.join(\"..\", \"input\", \"ddsm-mammography\", \"training10_2\", \"training10_2.tfrecords\")\n","        train_path_13 = os.path.join(\"..\", \"input\", \"ddsm-mammography\", \"training10_3\", \"training10_3.tfrecords\")\n","\n","        train_files = [train_path_10, train_path_11, train_path_12, train_path_13]\n","        total_records = 44712\n","    else:\n","        raise ValueError('Invalid dataset!')\n","\n","    return train_files, total_records\n","\n","def get_test_data(what=10):\n","    test_files = os.path.join(\"..\", \"input\", \"ddsm-mammography\", \"training10_4\", \"training10_4.tfrecords\")\n","    \n","    return [test_files], 11178\n","\n","def _conv2d_batch_norm(input, filters, kernel_size=(3,3), stride=(1,1), training = tf.placeholder(dtype=tf.bool, name=\"is_training\"), epsilon=1e-8, padding=\"SAME\", seed=None, lambd=0.0, name=None, activation=\"relu\"):\n","    with tf.name_scope('layer_'+name) as scope:\n","        conv = tf.layers.conv2d(\n","            input,\n","            filters=filters,\n","            kernel_size=kernel_size,\n","            strides=stride,\n","            padding=padding,\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=seed),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lambd),\n","            name='conv_'+name\n","        )\n","\n","        # apply batch normalization\n","        conv = tf.layers.batch_normalization(\n","            conv,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn_'+name\n","        )\n","\n","        if activation == \"relu\":\n","            # apply relu\n","            conv = tf.nn.relu(conv, name='relu_'+name)\n","        elif activation == \"elu\":\n","            conv = tf.nn.elu(conv, name=\"elu_\" + name)\n","\n","    return conv"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"373b2cd7-8d34-4d3c-9b18-cc734cda0bee","_uuid":"6d8f75507265b7ea89cc397002fc261f539edfba","trusted":true},"outputs":[],"source":["## ARGUMENTS\n","epochs = 1\n","dataset = 10\n","how = \"normal\"\n","action = \"eval\"\n","threshold = 0.5\n","contrast = 1\n","weight = 7.0\n","distort = False\n","\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"063e9183-960a-4a96-bc11-246b84720d56","_uuid":"91044dd38f433b93fa5dc5cafca87059fe8e3d6d","trusted":true},"outputs":[],"source":["## Hyperparameters\n","epsilon = 1e-8\n","\n","# learning rate\n","epochs_per_decay = 5\n","decay_factor = 0.80\n","staircase = True\n","\n","# lambdas\n","lamC = 0.00001\n","lamF = 0.00250\n","\n","# use dropout\n","dropout = True\n","fcdropout_rate = 0.5\n","convdropout_rate = 0.001\n","pooldropout_rate = 0.1\n","\n","num_classes = 2\n","train_files, total_records = get_training_data(what=dataset)\n","test_files, total_records = get_test_data(what=dataset)\n","print(\"Number of classes:\", num_classes)\n","\n","steps_per_epoch = int(total_records / batch_size)\n","print(\"Steps per epoch:\", steps_per_epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"323fc88f-f299-467c-88ca-f374051c9e1f","_uuid":"1a1b5f48bd09ae3dbbb30dfbd2c6769967392bb5","trusted":true},"outputs":[],"source":["##### Build the graph\n","graph = tf.Graph()\n","\n","model_name = \"model_s2.0.0.36b.10\"\n","\n","with graph.as_default():\n","    training = tf.placeholder(dtype=tf.bool, name=\"is_training\")\n","    is_testing = tf.placeholder(dtype=bool, shape=(), name=\"is_testing\")\n","\n","    # create global step for decaying learning rate\n","    global_step = tf.Variable(0, trainable=False)\n","\n","    learning_rate = tf.train.exponential_decay(0.001,\n","                                               global_step,\n","                                               1366,\n","                                               decay_factor,\n","                                               staircase=staircase)\n","\n","    with tf.name_scope('inputs') as scope:\n","        image, label = read_and_decode_single_example(test_files, label_type=how, normalize=False, distort=False)\n","\n","        X_def, y_def = tf.train.shuffle_batch([image, label], batch_size=batch_size, capacity=2000,\n","                                              seed=None,\n","                                              min_after_dequeue=1000)\n","\n","        # Placeholders\n","        X = tf.placeholder_with_default(X_def, shape=[None, None, None, 1])\n","        y = tf.placeholder_with_default(y_def, shape=[None])\n","\n","        # cast to float and scale input data\n","        X_adj = tf.cast(X, dtype=tf.float32)\n","        X_adj = _scale_input_data(X_adj, contrast=contrast, mu=127.0, scale=255.0)\n","\n","        # optional online data augmentation\n","        if distort:\n","            X_adj, y = augment(X_adj, y, horizontal_flip=True, vertical_flip=True, mixup=0)\n","\n","    # Convolutional layer 1\n","    with tf.name_scope('conv1') as scope:\n","        conv1 = tf.layers.conv2d(\n","            X_adj,\n","            filters=32,\n","            kernel_size=(3, 3),\n","            strides=(2, 2),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=100),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv1'\n","        )\n","\n","        conv1 = tf.layers.batch_normalization(\n","            conv1,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn1'\n","        )\n","\n","        # apply relu\n","        conv1_bn_relu = tf.nn.relu(conv1, name='relu1')\n","\n","    with tf.name_scope('conv1.1') as scope:\n","        conv11 = tf.layers.conv2d(\n","            conv1_bn_relu,\n","            filters=32,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=101),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv1.1'\n","        )\n","\n","        conv11 = tf.layers.batch_normalization(\n","            conv11,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn1.1'\n","        )\n","\n","        # apply relu\n","        conv11 = tf.nn.relu(conv11, name='relu1.1')\n","\n","\n","    with tf.name_scope('conv1.2') as scope:\n","        conv12 = tf.layers.conv2d(\n","            conv11,\n","            filters=32,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=1101),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv1.2'\n","        )\n","\n","        conv12 = tf.layers.batch_normalization(\n","            conv12,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn1.2'\n","        )\n","\n","        # apply relu\n","        conv12 = tf.nn.relu(conv12, name='relu1.1')\n","\n","    # Max pooling layer 1\n","    with tf.name_scope('pool1') as scope:\n","        pool1 = tf.layers.max_pooling2d(\n","            conv12,\n","            pool_size=(3, 3), \n","            strides=(2, 2),\n","            padding='SAME',\n","            name='pool1'\n","        )\n","\n","        # optional dropout\n","        if dropout:\n","            pool1 = tf.layers.dropout(pool1, rate=pooldropout_rate, seed=103, training=training)\n","\n","    # Convolutional layer 2\n","    with tf.name_scope('conv2.1') as scope:\n","        conv2 = tf.layers.conv2d(\n","            pool1,\n","            filters=64,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=104),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv2.1'\n","        )\n","\n","        conv2 = tf.layers.batch_normalization(\n","            conv2,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn2.1'\n","        )\n","\n","        # apply relu\n","        conv2 = tf.nn.relu(conv2, name='relu2.1')\n","\n","    # Convolutional layer 2\n","    with tf.name_scope('conv2.2') as scope:\n","        conv22 = tf.layers.conv2d(\n","            conv2,\n","            filters=64,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=1104),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv2.2'\n","        )\n","\n","        conv22 = tf.layers.batch_normalization(\n","            conv22,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn2.2'\n","        )\n","\n","        # apply relu\n","        conv22 = tf.nn.relu(conv22, name='relu2.2')\n","\n","    # Max pooling layer 2\n","    with tf.name_scope('pool2') as scope:\n","        pool2 = tf.layers.max_pooling2d(\n","            conv22,\n","            pool_size=(2, 2),\n","            strides=(2, 2),\n","            padding='SAME',\n","            name='pool2'\n","        )\n","\n","        # optional dropout\n","        if dropout:\n","            pool2 = tf.layers.dropout(pool2, rate=pooldropout_rate, seed=106, training=training)\n","\n","    # Convolutional layer 3\n","    with tf.name_scope('conv3.1') as scope:\n","        conv3 = tf.layers.conv2d(\n","            pool2,\n","            filters=128,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=107),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv3.1'\n","        )\n","\n","        conv3 = tf.layers.batch_normalization(\n","            conv3,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn3.1'\n","        )\n","\n","        # apply relu\n","        conv3 = tf.nn.relu(conv3, name='relu3.1')\n","\n","    # Convolutional layer 3\n","    with tf.name_scope('conv3.2') as scope:\n","        conv32 = tf.layers.conv2d(\n","            conv3,\n","            filters=128,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=1107),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv3.2'\n","        )\n","\n","        conv32 = tf.layers.batch_normalization(\n","            conv32,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn3.2'\n","        )\n","\n","        # apply relu\n","        conv32 = tf.nn.relu(conv32, name='relu3.2')\n","\n","    # Max pooling layer 3\n","    with tf.name_scope('pool3') as scope:\n","        pool3 = tf.layers.max_pooling2d(\n","            conv32,\n","            pool_size=(2, 2),\n","            strides=(2, 2),\n","            padding='SAME',\n","            name='pool3'\n","        )\n","\n","        if dropout:\n","            pool3 = tf.layers.dropout(pool3, rate=pooldropout_rate, seed=109, training=training)\n","\n","    # Convolutional layer 4\n","    with tf.name_scope('conv4') as scope:\n","            conv4 = tf.layers.conv2d(\n","                pool3,\n","                filters=256,\n","                kernel_size=(3, 3),\n","                strides=(1, 1),\n","                padding='SAME',\n","                activation=None,\n","                kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=110),\n","                kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","                name='conv4'\n","            )\n","\n","            conv4 = tf.layers.batch_normalization(\n","                conv4,\n","                axis=-1,\n","                momentum=0.99,\n","                epsilon=epsilon,\n","                center=True,\n","                scale=True,\n","                beta_initializer=tf.zeros_initializer(),\n","                gamma_initializer=tf.ones_initializer(),\n","                moving_mean_initializer=tf.zeros_initializer(),\n","                moving_variance_initializer=tf.ones_initializer(),\n","                training=training,\n","                name='bn4'\n","            )\n","\n","            # apply relu\n","            conv4_bn_relu = tf.nn.relu(conv4, name='relu4')\n","\n","    # Max pooling layer 4\n","    with tf.name_scope('pool4') as scope:\n","            pool4 = tf.layers.max_pooling2d(\n","                conv4_bn_relu,\n","                pool_size=(2, 2),\n","                strides=(2, 2),\n","                padding='SAME',\n","                name='pool4'\n","            )\n","\n","            if dropout:\n","                pool4 = tf.layers.dropout(pool4, rate=pooldropout_rate, seed=112, training=training)\n","\n","    # Convolutional layer 5\n","    with tf.name_scope('conv5') as scope:\n","        conv5 = tf.layers.conv2d(\n","            pool4,\n","            filters=512,\n","            kernel_size=(3, 3),\n","            strides=(1, 1),\n","            padding='SAME',\n","            activation=None,\n","            kernel_initializer=tf.truncated_normal_initializer(stddev=5e-2, seed=113),\n","            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=lamC),\n","            name='conv5'\n","        )\n","\n","        conv5 = tf.layers.batch_normalization(\n","            conv5,\n","            axis=-1,\n","            momentum=0.99,\n","            epsilon=epsilon,\n","            center=True,\n","            scale=True,\n","            beta_initializer=tf.zeros_initializer(),\n","            gamma_initializer=tf.ones_initializer(),\n","            moving_mean_initializer=tf.zeros_initializer(),\n","            moving_variance_initializer=tf.ones_initializer(),\n","            training=training,\n","            name='bn5'\n","        )\n","\n","        # apply relu\n","        conv5_bn_relu = tf.nn.relu(conv5, name='relu5')\n","\n","    # Max pooling layer 4\n","    with tf.name_scope('pool5') as scope:\n","        pool5 = tf.layers.max_pooling2d(\n","            conv5_bn_relu,\n","            pool_size=(2, 2),\n","            strides=(2, 2),\n","            padding='SAME',\n","            name='pool5'\n","        )\n","\n","        if dropout:\n","            pool5 = tf.layers.dropout(pool5, rate=pooldropout_rate, seed=115, training=training)\n","\n","    fc1 = _conv2d_batch_norm(pool5, 2048, kernel_size=(5, 5), stride=(5, 5), training=training, epsilon=1e-8,\n","                             padding=\"VALID\", seed=1013, lambd=lamC, name=\"fc_1\")\n","\n","    fc2 = _conv2d_batch_norm(fc1, 2048, kernel_size=(1, 1), stride=(1, 1), training=training, epsilon=1e-8,\n","                             padding=\"VALID\", seed=1014, lambd=lamC, name=\"fc_2\")\n","\n","    fc3 = tf.layers.dense(\n","        fc2,\n","        num_classes,  # One output unit per category\n","        activation=None,  # No activation function\n","        kernel_initializer=tf.variance_scaling_initializer(scale=1, seed=121),\n","        bias_initializer=tf.zeros_initializer(),\n","        name=\"fc_logits\"\n","    )\n","\n","    logits = tf.squeeze(fc3, name=\"fc_flat_logits\")\n","\n","    # get the fully connected variables so we can only train them when retraining the network\n","    fc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"fc\")\n","\n","    with tf.variable_scope('conv1', reuse=True):\n","        conv_kernels1 = tf.get_variable('kernel')\n","        kernel_transposed = tf.transpose(conv_kernels1, [3, 0, 1, 2])\n","\n","    with tf.variable_scope('visualization'):\n","        tf.summary.image('conv1/filters', kernel_transposed, max_outputs=32, collections=[\"kernels\"])\n","\n","    # This will weight the positive examples higher so as to improve recall\n","    weights = tf.multiply(weight, tf.cast(tf.greater(y, 0), tf.float32)) + 1\n","    mean_ce = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits, weights=weights))\n","\n","    # Add in l2 loss\n","    loss = mean_ce + tf.losses.get_regularization_loss()\n","\n","    # Adam optimizer\n","    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","\n","    train_op = optimizer.minimize(loss, global_step=global_step)\n","\n","    # get the probabilites for the classes\n","    probabilities = tf.nn.softmax(logits, name=\"probabilities\")\n","    abnormal_probability = 1 - probabilities[:,0]\n","\n","    # Compute predictions from the probabilities\n","    if threshold == 0.5:\n","        predictions = tf.argmax(probabilities, axis=1, output_type=tf.int32)\n","    else:\n","        predictions = tf.cast(tf.greater(abnormal_probability, threshold), tf.int32)\n","\n","    # get the accuracy\n","    accuracy, acc_op = tf.metrics.accuracy(\n","        labels=y,\n","        predictions=predictions,\n","        updates_collections=tf.GraphKeys.UPDATE_OPS,\n","        name=\"accuracy\",\n","    )\n","\n","    recall, rec_op = tf.metrics.recall(labels=y, predictions=predictions, updates_collections=tf.GraphKeys.UPDATE_OPS, name=\"recall\")\n","    precision, prec_op = tf.metrics.precision(labels=y, predictions=predictions, updates_collections=tf.GraphKeys.UPDATE_OPS, name=\"precision\")\n","\n","    f1_score = 2 * ((precision * recall) / (precision + recall))\n","\n","    # Create summary hooks\n","    tf.summary.scalar('accuracy', accuracy, collections=[\"summaries\"])\n","    tf.summary.scalar('cross_entropy', mean_ce, collections=[\"summaries\"])\n","    tf.summary.scalar('learning_rate', learning_rate, collections=[\"summaries\"])\n","\n","    # add this so that the batch norm gets run\n","    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n","\n","    # Merge all the summaries\n","    merged = tf.summary.merge_all(\"summaries\")\n","\n","    print(\"Graph created...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"beda6f27-f3da-470a-9eee-268bf40d9a7e","_uuid":"a210632ca0c39d20103cc5d92354ca16e255d5d8","trusted":true},"outputs":[],"source":["## CONFIGURE OPTIONS\n","init = False\n","print_every = 5  # how often to print metrics\n","checkpoint_every = 1  # how often to save model in epochs\n","print_metrics = True  # whether to print or plot metrics, if False a plot will be created and updated every epoch\n","\n","config = tf.ConfigProto()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"985b7e9215b355b538a8aba00fc515a4a56d8993","trusted":true},"outputs":[],"source":["# copy the checkpoints\n","!mkdir ./model\n","!cp ../input/fcn-trained-on-ddsm-images/* ./model/"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"65642bdf7b7b029daf76501f0f8e4106e9fc25db","trusted":true},"outputs":[],"source":["action = \"eval\"\n","init = False\n","\n","## train the model\n","with tf.Session(graph=graph, config=config) as sess:\n","    # create the saver\n","    saver = tf.train.Saver()\n","    \n","    # If the model is new initialize variables, else restore the session\n","    if init:\n","        sess.run(tf.global_variables_initializer())\n","        print(\"Initializing model...\")\n","    else:\n","        saver.restore(sess, './model/' + model_name + '.ckpt')\n","        print(\"Restoring model\", model_name)\n","    \n","    coord = tf.train.Coordinator()\n","    threads = tf.train.start_queue_runners(coord=coord)\n","        \n","    # if we are training the model\n","    if action == \"train\":\n","\n","        print(\"Training model\", model_name, \"...\")\n","\n","        for epoch in range(epochs):\n","            sess.run(tf.local_variables_initializer())\n","\n","            for i in range(steps_per_epoch):\n","                # create the metadata\n","                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n","                run_metadata = tf.RunMetadata()\n","\n","                _, precision_value, summary, acc_value, cost_value, recall_value = sess.run(\n","                    [extra_update_ops, prec_op, merged, accuracy, mean_ce, rec_op],\n","                    feed_dict={\n","                        training: True,\n","                    },\n","                    options=run_options,\n","                    run_metadata=run_metadata)\n","                \n","            # save checkpoint every nth epoch\n","            if (epoch % checkpoint_every == 0):\n","                print(\"Saving checkpoint\")\n","                save_path = saver.save(sess, './model/' + model_name + '.ckpt')\n","\n","                # Now that model is saved set init to false so we reload it next time\n","                init = False\n","    else:\n","        sess.run(tf.local_variables_initializer())\n","        \n","        # evaluate the test data\n","        for i in range(steps_per_epoch-1):\n","            valid_acc, valid_recall, valid_precision = sess.run(\n","                [acc_op, rec_op, prec_op],\n","                feed_dict={\n","                    training: False\n","                })\n","\n","        # evaluate once more to get the summary\n","        cv_recall, cv_precision, cv_accuracy = sess.run(\n","            [recall, precision, accuracy],\n","            feed_dict={\n","                training: False\n","            })\n","\n","        print(\"Test Accuracy:\", cv_accuracy)\n","        print(\"Test Recall:\", cv_recall)\n","        print(\"Test Precision:\", cv_precision)\n","        \n","    # stop the coordinator and the threads\n","    coord.request_stop()\n","    coord.join(threads)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd60a388-f2d2-45e8-9b60-b8d6d4ca752d","_uuid":"acb830fab334c5e4fc0159cd539ecb2995f1280c","trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":1}
